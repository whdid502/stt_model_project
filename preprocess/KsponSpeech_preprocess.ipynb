{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KsponSpeech-preprocess.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RMRocAAVFMs"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install sentencepiece\n",
        "!pip install hgtk\n",
        "!pip install gluonnlp\n",
        "\n",
        "!git clone https://github.com/SKTBrain/KoBERT.git\n",
        "!pip install -r KoBERT/requirements.txt\n",
        "!pip install KoBERT/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMmYt1EA7m48"
      },
      "source": [
        "## 1. Base Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk8OcoJx7pmk"
      },
      "source": [
        "## 2. Data-Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_jpxcyF4EAj"
      },
      "source": [
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "TEMP = BASE_PATH + '/' + 'KsponSpeech_01' + '/' + 'KsponSpeech_0001' + '/' + 'KsponSpeech_000001' + '.txt'\n",
        "print(TEMP)\n",
        "\n",
        "with open(TEMP, 'r', encoding='ms949') as f:\n",
        "   r = f.read()\n",
        "   print(r)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDcLv75V7q9l"
      },
      "source": [
        "def bracket_filter(sentence):\n",
        "    new_sentence = ''\n",
        "    flag = True\n",
        "\n",
        "    for ch in sentence:\n",
        "        if ch == '(':\n",
        "            continue\n",
        "        if ch == ')':\n",
        "            if flag == True:\n",
        "                flag = False\n",
        "                continue\n",
        "            else:\n",
        "                flag = True\n",
        "                continue\n",
        "        if ch != ')' and flag == True:\n",
        "            new_sentence += ch\n",
        "            \n",
        "    return new_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bGmLZ6hccm7"
      },
      "source": [
        "test = 'o/ 근데 (70%)/(칠십 퍼센트)가 커 보이긴 하는데 (200)/(이백) 벌다 (140)/(백 사십) 벌면 빠+ 빡셀걸? b/'\n",
        "print(bracket_filter(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRmSWYvk86P9"
      },
      "source": [
        "def special_filter(sentence):\n",
        "    SENTENCE_MARK = ['.', '?', ',', '!']\n",
        "    NOISE = ['o', 'n', 'u', 'b', 'l']\n",
        "    EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';']\n",
        "\n",
        "    import re\n",
        "    \n",
        "    new_sentence = ''\n",
        "    for idx, ch in enumerate(sentence):\n",
        "        if ch not in SENTENCE_MARK:\n",
        "            # o/, n/ 등을 처리\n",
        "            if idx + 1 < len(sentence) and ch in NOISE and sentence[idx+1] == '/':\n",
        "                continue\n",
        "        # if ch == 'l':\n",
        "        #     new_sentence += '(웃으며)'\n",
        "        if ch == '+':\n",
        "            new_sentence += ','\n",
        "        if ch not in EXCEPT:\n",
        "            new_sentence += ch\n",
        "    pattern = re.compile(r'\\s\\s+')\n",
        "    new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
        "    return new_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdu190ruArYw"
      },
      "source": [
        "test = 'o/ 근데 (70%)/(칠십 퍼센트)가 커 보이긴 하는데 (200)/(이백) 벌다 (140)/(백 사십) 벌면 빠+ 빡셀걸? b/'\n",
        "print(special_filter(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6HlKyxCGoG"
      },
      "source": [
        "def sentence_filter(raw_sentence):\n",
        "    return special_filter(bracket_filter(raw_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa3SjIc4eOxL"
      },
      "source": [
        "test = 'o/ 근데 (70%)/(칠십 퍼센트)가 커 보이긴 하는데 (200)/(이백) 벌다 (140)/(백 사십) 벌면 빠+ 빡셀걸? b/'\n",
        "print(sentence_filter(test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuon8EsCCzbB"
      },
      "source": [
        "with open(TEMP, 'r', encoding='ms949') as f:\n",
        "   r = f.read()\n",
        "   print(sentence_filter(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtK2uwcaC6Qo"
      },
      "source": [
        "## 3. Create Character labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03hk8c-a3otX"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "\n",
        "label_list = []\n",
        "label_freq = []\n",
        "\n",
        "temp = os.listdir(BASE_PATH)\n",
        "# f1_names = [t for t in temp if 'KsponSpeech_0' in t]\n",
        "f1_names = ['KsponSpeech_01']\n",
        "print(f1_names)\n",
        "\n",
        "for f1 in f1_names:\n",
        "    print(f'----- {f1} started... ')\n",
        "    f2_names = os.listdir(BASE_PATH + f1 + '/')\n",
        "    for f2 in f2_names:\n",
        "        print(f'---------- {f2} started... ')\n",
        "        f_names = os.listdir(BASE_PATH + f1 + '/' + f2 + '/')\n",
        "        for fn in f_names:\n",
        "            if '.txt' not in fn:\n",
        "                continue\n",
        "            with open(BASE_PATH + f1 + '/' + f2 + '/' + fn, 'r', encoding='ms949') as f:\n",
        "                sentence = sentence_filter(f.readline())\n",
        "            for ch in sentence:\n",
        "                if ch not in label_list:\n",
        "                    label_list.append(ch)\n",
        "                    label_freq.append(1)\n",
        "                else:\n",
        "                    label_freq[label_list.index(ch)] += 1\n",
        "\n",
        "\n",
        "label_freq, label_list = zip(*sorted(zip(label_freq, label_list), reverse=True))\n",
        "label = {'id': [0, 1, 2], 'char': ['_', '<s>', '</s>'], 'freq': [0, 0, 0]}\n",
        "for idx, (ch, freq) in enumerate(zip(label_list, label_freq)):\n",
        "    label['id'].append(idx+3)\n",
        "    label['char'].append(ch)\n",
        "    label['freq'].append(freq)\n",
        "\n",
        "label_df = pd.DataFrame(label)\n",
        "label_df.to_csv('aihub_labels.csv', encoding='ms949', index=False)\n",
        "print(label_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgtlHHY6KfKU"
      },
      "source": [
        "## 4. Create target text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22aZYZXKhVr"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_label(file_path):\n",
        "    char2id = {}\n",
        "    id2char = {}\n",
        "    ch_labels = pd.read_csv(file_path, encoding='ms949')\n",
        "    id_list = ch_labels['id']\n",
        "    char_list = ch_labels['char']\n",
        "    freq_list = ch_labels['freq']\n",
        "\n",
        "    for (id, char, freq) in zip(id_list, char_list, freq_list):\n",
        "        char2id[char] = id\n",
        "        id2char[id] = char\n",
        "    return char2id, id2char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRRdqDSLI9G"
      },
      "source": [
        "def sentence_to_target(sentence, char2id):\n",
        "    target = ''\n",
        "    for ch in sentence:\n",
        "        target += (str(char2id[ch]) + ' ')\n",
        "    return target[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJLIpD6kLegW"
      },
      "source": [
        "def target_to_sentence(target, id2char):\n",
        "    sentence = ''\n",
        "    targets = target.split()\n",
        "\n",
        "    for n in targets:\n",
        "        sentence += id2char[int(n)]\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgdjxHoyNw6m"
      },
      "source": [
        "file_path = '/content/aihub_labels.csv'\n",
        "char2id, id2char = load_label(file_path)\n",
        "\n",
        "test = '오늘 뭐 먹지?'\n",
        "\n",
        "a = sentence_to_target(test, char2id)\n",
        "print(a)\n",
        "\n",
        "b = target_to_sentence(a, id2char)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GC3dUcpFvG6x"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "\n",
        "temp = os.listdir(BASE_PATH)\n",
        "# f1_names = [t for t in temp if 'KsponSpeech_0' in t]\n",
        "f1_names = ['KsponSpeech_01']\n",
        "print(f1_names)\n",
        "\n",
        "char2id, id2char = load_label('aihub_labels.csv')\n",
        "total_fn = 0\n",
        "\n",
        "for f1 in f1_names:\n",
        "    print(f'----- {f1} started... ')\n",
        "    f2_names = os.listdir(BASE_PATH + f1 + '/')\n",
        "    for f2 in f2_names:\n",
        "        print(f'---------- {f2} started... ')\n",
        "        f_names = os.listdir(BASE_PATH + f1 + '/' + f2 + '/')\n",
        "        for fn in f_names:\n",
        "            if '.txt' not in fn:\n",
        "                continue\n",
        "            total_fn += 1\n",
        "            with open(BASE_PATH + f1 + '/' + f2 + '/' + fn, 'r', encoding='ms949') as f:\n",
        "                sentence = sentence_filter(f.readline())\n",
        "            with open(BASE_PATH + f1 + '/' + f2 + '/' + 'KsponSpeech_label_' + fn.split('_')[1][:6] + '.txt', 'w', encoding='ms949') as f:\n",
        "                target = sentence_to_target(sentence, char2id)\n",
        "                f.write(target)\n",
        "print('----- ended!!! ')\n",
        "print(total_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SZYhNm4QjAB"
      },
      "source": [
        "## 5. Create data list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3lJiH9QnNw"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('aihub_labels.csv', encoding='ms949')\n",
        "start1 = len(df) - len(df[df.freq == 1]) + 1\n",
        "\n",
        "# total_fn = ??? (위에서 계산)\n",
        "train_num = int(total_fn * 0.98)\n",
        "test_num = total_fn - train_num\n",
        "\n",
        "train_data_list = {'audio': [], 'label': []}\n",
        "test_data_list = {'audio': [], 'label': []}\n",
        "\n",
        "aihub_labels = pd.read_csv('aihub_labels.csv', encoding='ms949')\n",
        "rare_labels = aihub_labels['char'][start1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5uMjz8s4Pgs"
      },
      "source": [
        "import os\n",
        "\n",
        "audio_paths = []\n",
        "target_paths = []\n",
        "\n",
        "temp = os.listdir(BASE_PATH)\n",
        "# f1_names = [t for t in temp if 'KsponSpeech_0' in t]\n",
        "f1_names = ['KsponSpeech_01']\n",
        "print(f1_names)\n",
        "\n",
        "for f1 in f1_names:\n",
        "    print(f'----- {f1} started... ')\n",
        "    f2_names = os.listdir(BASE_PATH + f1 + '/')\n",
        "    for f2 in f2_names:\n",
        "        print(f'---------- {f2} started... ')\n",
        "        f_names = os.listdir(BASE_PATH + f1 + '/' + f2 + '/')\n",
        "        for fn in f_names:\n",
        "            if '.pcm' in fn:\n",
        "                audio_paths.append(f1 + '/' + f2 + '/' + fn)\n",
        "            if 'KsponSpeech_label_' in fn:\n",
        "                target_paths.append(f1 + '/' + f2 + '/' + fn)\n",
        "\n",
        "print('----- ended!!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVkXL6RFPzDM"
      },
      "source": [
        "import random\n",
        "\n",
        "data_paths = list(zip(audio_paths, target_paths))\n",
        "random.shuffle(data_paths)\n",
        "audio_paths, target_paths = zip(*data_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjzXz7UtQg3a"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "path = '/content/drive/My Drive/googledrive/'\n",
        "train_full = False\n",
        "train_dict = {'audio': [], 'label': []}\n",
        "test_dict = {'audio': [], 'label': []}\n",
        "\n",
        "print('started...')\n",
        "for idx in trange(len(audio_paths)):\n",
        "    audio = audio_paths[idx]\n",
        "    target = target_paths[idx]\n",
        "    if len(train_dict['audio']) == train_num:\n",
        "        train_full = True\n",
        "    if train_full:\n",
        "        test_dict['audio'].append(audio)\n",
        "        test_dict['label'].append(target)\n",
        "    else:\n",
        "        rare_in = False\n",
        "        sentence = None\n",
        "        with open((path+audio).split('.')[0]+'.txt', encoding='ms949') as f:\n",
        "            sentence = f.readline()\n",
        "            \n",
        "        for rare in rare_labels:\n",
        "            if rare in sentence:\n",
        "                rare_in = True\n",
        "                break\n",
        "        if rare_in:\n",
        "            test_dict['audio'].append(audio)\n",
        "            test_dict['label'].append(target)\n",
        "        else:\n",
        "            train_dict['audio'].append(audio)\n",
        "            train_dict['label'].append(target)\n",
        "            \n",
        "print('\\n\\n Ended!!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d06j186AYOZo"
      },
      "source": [
        "test_df = pd.DataFrame(test_dict)\n",
        "train_df = pd.DataFrame(train_dict)\n",
        "\n",
        "test_df.to_csv('test_list.csv', encoding='ms949', index=False)\n",
        "train_df.to_csv('train_list.csv', encoding='ms949', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZijhGdKTx1I"
      },
      "source": [
        "## To-Do List\n",
        "- 전체적으로 실행 후 오류 수정 필요\n",
        "- special_filter() 함수 수정 필요: 한숨, 침묵 등 처리 방법에 대한 논의 필요\n",
        "- f1_names = ['KsponSpeech_01'] 테스트로 3개 바꿔놓음"
      ]
    }
  ]
}