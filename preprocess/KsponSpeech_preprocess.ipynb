{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KsponSpeech-preprocess.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RMRocAAVFMs"
      },
      "source": [
        "!pip install pandas\n",
        "!pip install sentencepiece\n",
        "!pip install hgtk\n",
        "!pip install gluonnlp\n",
        "\n",
        "!git clone https://github.com/SKTBrain/KoBERT.git\n",
        "!pip install -r KoBERT/requirements.txt\n",
        "!pip install KoBERT/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMmYt1EA7m48"
      },
      "source": [
        "## 1. Base Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eh807B-cVEqx"
      },
      "source": [
        "def file_num_padding(file_num):\n",
        "    if file_num < 10:\n",
        "        return '00000' + str(file_num)\n",
        "    elif file_num < 100:\n",
        "        return '0000' + str(file_num)\n",
        "    elif file_num < 1000:\n",
        "        return '000' + str(file_num)\n",
        "    elif file_num < 10000:\n",
        "        return '00' + str(file_num)\n",
        "    elif file_num < 100000:\n",
        "        return '0' + str(file_num)\n",
        "    else:\n",
        "        return str(file_num)\n",
        "\n",
        "def folder_1_padding(folder_num):\n",
        "    if folder_num < 10:\n",
        "        return '0' + str(folder_num) + '/'\n",
        "    else:\n",
        "        return str(folder_num) + '/'\n",
        "\n",
        "def folder_2_padding(folder_num):\n",
        "    if folder_num < 10:\n",
        "        return '000' + str(folder_num) + '/'\n",
        "    elif folder_num < 100:\n",
        "        return '00' + str(folder_num) + '/'\n",
        "    elif folder_num < 1000:\n",
        "        return '0' + str(folder_num) + '/'\n",
        "    else:\n",
        "        return str(folder_num) + '/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLSwtErb09uG"
      },
      "source": [
        "def get_path(path, fname, folder_1_num, folder_2_num, file_num, format):\n",
        "    folder_1_num = folder_1_padding(folder_1_num)\n",
        "    folder_2_num = folder_2_padding(folder_2_num)\n",
        "    file_num = file_num_padding(file_num)\n",
        "    return path + fname + folder_1_num + fname + folder_2_num + fname + file_num + format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_jpxcyF4EAj"
      },
      "source": [
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "fname = 'KsponSpeech_'\n",
        "folder_1_num = 1\n",
        "folder_2_num = 1\n",
        "file_num = 1\n",
        "format = '.txt'\n",
        "\n",
        "TEMP = get_path(BASE_PATH, fname, folder_1_num, folder_2_num, file_num, format)\n",
        "print(TEMP)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk8OcoJx7pmk"
      },
      "source": [
        "## 2. Data-Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDcLv75V7q9l"
      },
      "source": [
        "def bracket_filter(sentence):\n",
        "    new_sentence = ''\n",
        "    flag = False\n",
        "\n",
        "    for ch in sentence:\n",
        "        if ch == '(' and flag == False:\n",
        "            flag = True\n",
        "            continue\n",
        "        if ch == ')' and flag == True:\n",
        "            flag = False\n",
        "            continue\n",
        "        if ch != ')' and flag == False:\n",
        "            new_sentence += ch\n",
        "            \n",
        "    return new_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pCS3uFo8V-u"
      },
      "source": [
        "with open(TEMP, 'r', encoding='ms949') as f:\n",
        "   r = f.read()\n",
        "   print(bracket_filter(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRmSWYvk86P9"
      },
      "source": [
        "def special_filter(sentence):\n",
        "    SENTENCE_MARK = ['.', '?', ',', '!']\n",
        "    NOISE = ['o', 'n', 'u', 'b', 'l']\n",
        "    EXCEPT = ['/', '+', '*', '-', '@', '$', '^', '&', '[', ']', '=', ':', ';']\n",
        "\n",
        "    import re\n",
        "    \n",
        "    new_sentence = ''\n",
        "    for idx, ch in enumerate(sentence):\n",
        "        if ch not in SENTENCE_MARK:\n",
        "            # o/, n/ 등을 처리\n",
        "            if idx + 1 < len(sentence) and ch in NOISE and sentence[idx+1] == '/':\n",
        "                continue\n",
        "        if ch not in EXCEPT:\n",
        "            new_sentence += ch\n",
        "    pattern = re.compile(r'\\s\\s+')\n",
        "    new_sentence = re.sub(pattern, ' ', new_sentence.strip())\n",
        "    return new_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tdu190ruArYw"
      },
      "source": [
        "with open(TEMP, 'r', encoding='ms949') as f:\n",
        "   r = f.read()\n",
        "   print(special_filter(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ck6HlKyxCGoG"
      },
      "source": [
        "def sentence_filter(raw_sentence):\n",
        "    return special_filter(bracket_filter(raw_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuon8EsCCzbB"
      },
      "source": [
        "with open(TEMP, 'r', encoding='ms949') as f:\n",
        "   r = f.read()\n",
        "   print(sentence_filter(r))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtK2uwcaC6Qo"
      },
      "source": [
        "## 3. Create Character labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmnfjyTyC3fD"
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "fname = 'KsponSpeech_'\n",
        "format = '.txt'\n",
        "\n",
        "total_f1 = 1\n",
        "total_f2 = 4\n",
        "total_fn = 4000\n",
        "\n",
        "label_list = []\n",
        "label_freq = []\n",
        "\n",
        "now1 = 1\n",
        "now2 = 1\n",
        "\n",
        "print('started... \\n\\n')\n",
        "for f1 in trange(1, total_f1+1):\n",
        "    for f2 in trange(now1, now1+100):\n",
        "        if f2 > total_f2:\n",
        "            break\n",
        "        for fn in trange(now2, now2+1000):\n",
        "            if fn > total_fn:\n",
        "                break\n",
        "            with open(get_path(BASE_PATH, fname, f1, f2, fn, format), 'r', encoding='ms949') as f:\n",
        "                sentence = f.readline()\n",
        "            for ch in sentence:\n",
        "                if ch not in label_list:\n",
        "                    label_list.append(ch)\n",
        "                    label_freq.append(1)\n",
        "                else:\n",
        "                    label_freq[label_list.index(ch)] += 1\n",
        "        now2 += 1000\n",
        "    now1 += 100\n",
        "    \n",
        "\n",
        "# sort together Using zip\n",
        "label_freq, label_list = zip(*sorted(zip(label_freq, label_list), reverse=True))\n",
        "label = {'id': [0, 1, 2], 'char': ['_', '<s>', '</s>'], 'freq': [0, 0, 0]}\n",
        "for idx, (ch, freq) in enumerate(zip(label_list, label_freq)):\n",
        "    label['id'].append(idx)\n",
        "    label['char'].append(ch)\n",
        "    label['freq'].append(freq)\n",
        "\n",
        "# dictionary to csv\n",
        "label_df = pd.DataFrame(label)\n",
        "label_df.to_csv('aihub_labels.csv', encoding='ms949', index=False)\n",
        "print(label_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgtlHHY6KfKU"
      },
      "source": [
        "## 4. Create target text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22aZYZXKhVr"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_label(file_path):\n",
        "    char2id = {}\n",
        "    id2char = {}\n",
        "    ch_labels = pd.read_csv(file_path, encoding='ms949')\n",
        "    id_list = ch_labels['id']\n",
        "    char_list = ch_labels['char']\n",
        "    freq_list = ch_labels['freq']\n",
        "\n",
        "    for (id, char, freq) in zip(id_list, char_list, freq_list):\n",
        "        char2id[char] = id\n",
        "        id2char[id] = char\n",
        "    return char2id, id2char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDRRdqDSLI9G"
      },
      "source": [
        "def sentence_to_target(sentence, char2id):\n",
        "    target = ''\n",
        "    for ch in sentence:\n",
        "        target += (str(char2id[ch]) + ' ')\n",
        "    return target[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJLIpD6kLegW"
      },
      "source": [
        "def target_to_sentence(target, id2char):\n",
        "    sentence = ''\n",
        "    targets = target.split()\n",
        "\n",
        "    for n in targets:\n",
        "        sentence += id2char[int(n)]\n",
        "    return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgdjxHoyNw6m"
      },
      "source": [
        "file_path = '/content/aihub_labels.csv'\n",
        "char2id, id2char = load_label(file_path)\n",
        "\n",
        "test = '인공지능 사관학교 화이팅!'\n",
        "a = sentence_to_target(test, char2id)\n",
        "print(a)\n",
        "b = target_to_sentence(a, id2char)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzAB4F3vyEIk"
      },
      "source": [
        "def get_label_path(path, fname, folder_1_num, folder_2_num, file_num, format, new_fname):\n",
        "    folder_1_num = folder_1_padding(folder_1_num)\n",
        "    folder_2_num = folder_2_padding(folder_2_num)\n",
        "    file_num = file_num_padding(file_num)\n",
        "    return path + fname + folder_1_num + fname + folder_2_num + new_fname + file_num + format"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcpTJkqqOIqw"
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import trange\n",
        "\n",
        "BASE_PATH = '/content/drive/My Drive/googledrive/'\n",
        "fname = 'KsponSpeech_'\n",
        "format = '.txt'\n",
        "new_fname = 'KsponSpeech_label_'\n",
        "\n",
        "total_f1 = 1\n",
        "total_f2 = 4\n",
        "total_fn = 4000\n",
        "char2id, id2char = load_label('aihub_labels.csv')\n",
        "\n",
        "now1 = 1\n",
        "now2 = 1\n",
        "\n",
        "print('started... \\n\\n')\n",
        "for f1 in trange(1, total_f1+1):\n",
        "    for f2 in trange(now1, now1+100):\n",
        "        if f2 > total_f2:\n",
        "            break\n",
        "        for fn in trange(now2, now2+1000):\n",
        "            if fn > total_fn:\n",
        "                break\n",
        "            with open(get_path(BASE_PATH, fname, f1, f2, fn, format), 'r', encoding='ms949') as f:\n",
        "                sentence = f.readline()\n",
        "\n",
        "            with open(get_label_path(BASE_PATH, fname, f1, f2, fn, format, new_fname), 'w', encoding='ms949') as f:\n",
        "                target = sentence_to_target(sentence, char2id)\n",
        "                f.write(target)\n",
        "        now2 += 1000\n",
        "    now1 += 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SZYhNm4QjAB"
      },
      "source": [
        "## 5. Create data list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ3lJiH9QnNw"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "total_fn = 4000\n",
        "train_num = int(total_fn * 0.98)\n",
        "test_num = total_fn - train_num\n",
        "\n",
        "train_data_list = {'audio': [], 'label': []}\n",
        "test_data_list = {'audio': [], 'label': []}\n",
        "aihub_labels = pd.read_csv('aihub_labels.csv', encoding='ms949')\n",
        "rare_labels = aihub_labels['char'][996:]   # 슬라이싱 값 직접 설정 필요: rare_labels = aihub_labels['char'][index num (started 'freq == 1'):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76ZBVymXPAGr"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "fname = 'KsponSpeech_'\n",
        "target_fname = 'KsponSpeech_label_'\n",
        "\n",
        "audio_paths = []\n",
        "target_paths = []\n",
        "\n",
        "total_f1 = 1\n",
        "total_f2 = 4\n",
        "\n",
        "now1 = 1\n",
        "now2 = 1\n",
        "\n",
        "for f1 in trange(1, total_f1+1):\n",
        "    for f2 in trange(now1, now1+100):\n",
        "        if f2 > total_f2:\n",
        "            break\n",
        "        for fn in trange(now2, now2+1000):\n",
        "            if fn > total_fn:\n",
        "                break\n",
        "            audio_paths.append(get_path('', fname, f1, f2, fn, '.pcm'))\n",
        "            target_paths.append(get_label_path('', fname, f1, f2, fn, '.txt', target_fname))\n",
        "        now2 += 1000\n",
        "    now1 += 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVkXL6RFPzDM"
      },
      "source": [
        "import random\n",
        "\n",
        "data_paths = list(zip(audio_paths, target_paths))\n",
        "random.shuffle(data_paths)\n",
        "audio_paths, target_paths = zip(*data_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjzXz7UtQg3a"
      },
      "source": [
        "from tqdm import trange\n",
        "\n",
        "path = '/content/drive/My Drive/googledrive/'\n",
        "train_full = False\n",
        "train_dict = {'audio': [], 'label': []}\n",
        "test_dict = {'audio': [], 'label': []}\n",
        "\n",
        "print('started...')\n",
        "for idx in trange(len(audio_paths)):\n",
        "    audio = audio_paths[idx]\n",
        "    target = target_paths[idx]\n",
        "    if len(train_dict['audio']) == train_num:\n",
        "        train_full = True\n",
        "    if train_full:\n",
        "        test_dict['audio'].append(audio)\n",
        "        test_dict['label'].append(target)\n",
        "    else:\n",
        "        rare_in = False\n",
        "        sentence = None\n",
        "        with open((path+audio).split('.')[0]+'.txt', encoding='ms949') as f:\n",
        "            sentence = f.readline()\n",
        "            \n",
        "        for rare in rare_labels:\n",
        "            if rare in sentence:\n",
        "                rare_in = True\n",
        "                break\n",
        "        if rare_in:\n",
        "            test_dict['audio'].append(audio)\n",
        "            test_dict['label'].append(target)\n",
        "        else:\n",
        "            train_dict['audio'].append(audio)\n",
        "            train_dict['label'].append(target)\n",
        "            \n",
        "print('\\n\\n Ended!!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d06j186AYOZo"
      },
      "source": [
        "test_df = pd.DataFrame(test_dict)\n",
        "train_df = pd.DataFrame(train_dict)\n",
        "\n",
        "test_df.to_csv('test_list.csv', encoding='ms949', index=False)\n",
        "train_df.to_csv('train_list.csv', encoding='ms949', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZijhGdKTx1I"
      },
      "source": [
        "- total_f1, total_f2, total_fn: 사용 시 실제 값에 맞도록 수정 필요 (1, 4, 4000으로 임의 설정하여 테스트 진행 중)\n",
        "- Create data list에서 rare_label 슬라이싱 값 실제 값에 맞도록 수동 설정 필요 (가능하면 변수로 만드는 것도 좋을 듯)"
      ]
    }
  ]
}