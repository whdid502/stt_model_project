{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pcm to mfcc.ipynb",
      "provenance": [],
      "mount_file_id": "1E9XMwVJOP_7vviTEtchyWhLIJtjfGQ_-",
      "authorship_tag": "ABX9TyOL0F1ITDeQgYocz0Cyk7+p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whdid502/stt_model_project/blob/feature_extraction/pcm_to_mfcc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbEm92BLqOgp"
      },
      "source": [
        "tensorflow 1.13.2 버전 필요"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHzTWbl9pmnL",
        "outputId": "42f1645a-c15f-4843-a354-33fcb89994e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "!pip install tensorflow==1.13.2"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.13.2 in /usr/local/lib/python3.6/dist-packages (1.13.2)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.13.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.35.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.13.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (3.12.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.0.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (1.1.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.2) (0.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (1.0.1)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.2) (4.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.2) (50.3.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.2) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.2) (3.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltr66vdupw-5",
        "outputId": "f47a72c6-5021-4198-9853-9052ea07f885",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "!pip3 install SpecAugment"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SpecAugment in /usr/local/lib/python3.6/dist-packages (1.2.5)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.6/dist-packages (from SpecAugment) (0.6.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from SpecAugment) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (1.4.1)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (1.15.0)\n",
            "Requirement already satisfied: resampy>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (0.2.2)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (2.1.8)\n",
            "Requirement already satisfied: numpy>=1.8.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (1.18.5)\n",
            "Requirement already satisfied: numba>=0.38.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (0.48.0)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (0.16.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from librosa->SpecAugment) (4.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->SpecAugment) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->SpecAugment) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->SpecAugment) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->SpecAugment) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->SpecAugment) (50.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.0->librosa->SpecAugment) (0.31.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODXTSpJappST"
      },
      "source": [
        "import wave\n",
        "import librosa\n",
        "import IPython.display as ipd\n",
        "# from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from specAugment import spec_augment_tensorflow\n",
        "from scipy.fftpack import dct\n",
        "import os"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzHS82sCSYpO"
      },
      "source": [
        "import matplotlib\n",
        "matplotlib.use('TKAgg')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5okYqNlLqWU1"
      },
      "source": [
        "pcm to mfcc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJoVpgWWNA5G"
      },
      "source": [
        "def pcm_to_mfcc(audio_path, noise_injection):\n",
        "\n",
        "  signal = np.memmap(audio_path, dtype='h', mode='r').astype('float32') # load audio\n",
        "  data = signal / 32767   # normalize audio\n",
        "\n",
        "  if noise_injection:           # noise injection\n",
        "    wn = np.random.randn(len(data))\n",
        "    data_wn = data + 0.005*wn\n",
        "  else:\n",
        "    data_wn = data\n",
        "  \n",
        "  sr = 16000\n",
        "  mel_spectrogram = librosa.feature.melspectrogram(y=data_wn, sr=sr, n_mels=256, hop_length=128, fmax=8000) # data to melspectrogram\n",
        "\n",
        "  warped_masked_spectrogram = spec_augment_tensorflow.spec_augment(mel_spectrogram=mel_spectrogram) # melspectrogram spec augmentation\n",
        "\n",
        "  num_ceps = 12\n",
        "  mfcc = dct(warped_masked_spectrogram, type=2, axis=1, norm='ortho')[:, 1 : (num_ceps + 1)] # mel spectrogram to mfcc\n",
        "\n",
        "  return mfcc"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ecuuQTzOVHn"
      },
      "source": [
        "output = pcm_to_mfcc('/content/drive/My Drive/googledrive/feature_test/KsponSpeech_000001.pcm', True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwqSWz05PHsk",
        "outputId": "17559f14-1928-41b7-943d-f965aa9c14ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "output.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(256, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGiR_3w_dkux"
      },
      "source": [
        "pcmfile 싹 가져오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvAy9Q3jjDCr"
      },
      "source": [
        "total_list = []\n",
        "def pcm_list(root_dir):\n",
        "    files = os.listdir(root_dir)\n",
        "    for file in files:\n",
        "        path = os.path.join(root_dir, file)\n",
        "\n",
        "        if os.path.isdir(path):\n",
        "            pcm_list(path)\n",
        "        total_list.append(path)\n",
        "\n",
        "    file_list_pcm = [file for file in total_list if file.endswith(\".pcm\")]\n",
        "    return file_list_pcm"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRUd9v_JUwrP",
        "outputId": "3f4ade45-63b8-4289-c1f5-a23aea69277f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "pcm_li = pcm_list('/content/drive/My Drive/googledrive/feature_test')\n",
        "print(pcm_li)\n",
        "print(len(pcm_li))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/content/drive/My Drive/googledrive/feature_test/KsponSpeech_000001.pcm', '/content/drive/My Drive/googledrive/feature_test/KsponSpeech_000002.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373004.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373007.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373006.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373003.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373002.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373001.pcm', '/content/drive/My Drive/googledrive/feature_test/test_folder_for_feature/KsponSpeech_373005.pcm']\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcKVsDtCyDIR"
      },
      "source": [
        "mfcc_list = []\n",
        "# train_count = 1\n",
        "\n",
        "def training(pcm):\n",
        "  mfcc_list.append(pcm_to_mfcc(pcm, False))\n",
        "  # print(train_count + '번째 훈련 시작')\n",
        "  print('인코더')\n",
        "  print('디코더')\n",
        "  print('훈련')\n",
        "  print('체크포인트')\n",
        "  print('현재 mfcc변환 개수 : ' + str(len(mfcc_list)))\n",
        "  # print(train_count) \n",
        "\n",
        "def training_process(pcm_li, batch_size):\n",
        "  convert_count = 0\n",
        "  if len(pcm_li) < batch_size:\n",
        "    for pcm in pcm_li:\n",
        "      training(pcm)\n",
        "      \n",
        "  else:\n",
        "    for pcm in pcm_li:\n",
        "      training(pcm)\n",
        "      convert_count += 1\n",
        "      if convert_count == batch_size:\n",
        "        break\n",
        "  if batch_size <= len(pcm_li):\n",
        "    next_list = pcm_li[batch_size:]\n",
        "    print('남은 pcm 개수 : ' + str(len(next_list)))\n",
        "    training_process(next_list, batch_size)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-IyJ7Prq_IU",
        "outputId": "7586e520-2254-40c5-b074-86c0887c0467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "training_process(pcm_li,3)\n",
        "# print(len(mfcc_list))\n",
        "# print(len(pcm_li))\n",
        "len(mfcc_list)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 1\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 2\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 3\n",
            "남은 pcm 개수 : 6\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 4\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 5\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 6\n",
            "남은 pcm 개수 : 3\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 7\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 8\n",
            "인코더\n",
            "디코더\n",
            "훈련\n",
            "체크포인트\n",
            "현재 mfcc변환 개수 : 9\n",
            "남은 pcm 개수 : 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC5OAuszATqH",
        "outputId": "2fff0f92-4b76-4ef0-da6a-da182f1b179b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "mfcc_list[2]"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.4893614e-01, -9.0331399e-01, -5.0934637e-01, ...,\n",
              "         4.5932502e-01,  5.0939888e-02,  1.9189888e-01],\n",
              "       [-1.9615728e-02, -4.1044268e-01, -1.2822321e-01, ...,\n",
              "         2.4337146e-01,  9.3780465e-02,  5.7286665e-02],\n",
              "       [ 1.1023341e-02, -3.5794504e-02,  9.7195044e-02, ...,\n",
              "         5.0411329e-02,  1.2286048e-01,  9.0374619e-02],\n",
              "       ...,\n",
              "       [-3.2053138e-03, -5.9474446e-03,  6.8540974e-03, ...,\n",
              "         2.1928856e-03,  1.0191158e-03, -2.6170702e-03],\n",
              "       [-2.0517674e-03, -3.5864846e-03,  4.3518217e-03, ...,\n",
              "         1.2334632e-03,  3.5185338e-04, -1.3425916e-03],\n",
              "       [-1.5453136e-03, -2.7536158e-03,  3.3146660e-03, ...,\n",
              "         1.1062571e-03, -1.3210310e-04, -8.7890454e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    }
  ]
}